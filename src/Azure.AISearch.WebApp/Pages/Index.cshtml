@page
@model IndexModel
@{
    ViewData["Title"] = "Search";
}
@section Scripts {
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: false });

        const { createApp, ref, watch } = Vue
        createApp({
            setup() {
                const scenarios = ref(@Html.Raw(JsonSerializer.Serialize(Model.Scenarios, JsonConfiguration.DefaultJsonOptions)));
                //const selectedScenario = ref(null);
                // mjh Set default
                const selectedScenario = ref(scenarios.value.length >= 6 ? scenarios.value[5] : null);
                const searchRequest = ref(@Html.Raw(JsonSerializer.Serialize(Model.SearchRequest, JsonConfiguration.DefaultJsonOptions)));
                var settingsValue = { showExplanation: false, showOptions: true };
                var settingsValueStorage = localStorage.getItem('settings');
                if (settingsValueStorage) {
                    settingsValue = JSON.parse(settingsValueStorage);
                }
                const settings = ref(settingsValue);

                // Update the search request when a scenario is selected.
                watch(selectedScenario, (newScenario) => {
                    if (newScenario) {
                        searchRequest.value = newScenario.searchRequest;
                    }
                });

                // Trigger logic for the default selected scenario
                if (selectedScenario.value) {
                    searchRequest.value = selectedScenario.value.searchRequest; // Trigger the effect of selecting the default
                }

                // Save settings when changed.
                watch(settings, (newSettings) => {
                    localStorage.setItem('settings', JSON.stringify(newSettings));
                }, { deep: true });

                // Update the sequence diagram whenever relevant properties change.
                watch(
                    () => [settings.value.showExplanation, searchRequest.value.engine, searchRequest.value.searchIndex, searchRequest.value.queryType, searchRequest.value.dataSource, searchRequest.value.useIntegratedVectorization],
                    () => showSequenceDiagram()
                );

                const drawMermaid = function (mermaidDiagram) {
                    const currentTheme = document.documentElement.getAttribute('data-bs-theme');
                    const mermaidTheme = currentTheme == 'dark' ? 'dark' : 'default';
                    const graphDefinition = "%%{init: {'theme':'" + mermaidTheme + "'}}%%" + mermaidDiagram;
                    mermaid.render('mermaidSvg', graphDefinition).then(({ svg, bindFunctions }) => {
                        const mermaidElement = document.getElementById('mermaid');
                        mermaidElement.innerHTML = svg;
                    });
                };

                const getAzureCognitiveSearchSequenceDiagram = function (sourceParticipant, queryType, searchIndex, useIntegratedVectorization, createAzureOpenAIParticipant) {
                    var mermaidDiagram = '';
                    mermaidDiagram += 'create participant ACS as Azure AI Search\n';

                    var mermaidDiagramIntegratedVectorization = '';
                    if (useIntegratedVectorization) {
                        // In case of integrated vectorization, the vector is generated by Azure AI Search first.
                        if (createAzureOpenAIParticipant) {
                            mermaidDiagramIntegratedVectorization += 'create participant AOAI as Azure OpenAI\n';
                        }
                        mermaidDiagramIntegratedVectorization += 'ACS->>AOAI: Generate vector for search query\n';
                        mermaidDiagramIntegratedVectorization += getAzureOpenAIVectorSequenceDiagram();
                        if (createAzureOpenAIParticipant) {
                            mermaidDiagramIntegratedVectorization += 'destroy AOAI\n';
                            mermaidDiagramIntegratedVectorization += 'AOAI-xACS: Vector for search query\n';
                        } else {
                            mermaidDiagramIntegratedVectorization += 'AOAI->>ACS: Vector for search query\n';
                        }
                    }

                    if (queryType == '@QueryType.TextStandard' || queryType == '@QueryType.TextSemantic') {
                        // Pure keyword search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using keywords\n`;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using keywords\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Keyword search results\n';
                    }
                    else if (queryType == '@QueryType.Vector') {
                        // Pure vector search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using vector\n`;
                        mermaidDiagram += mermaidDiagramIntegratedVectorization;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using vector\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Vector search results\n';
                    }
                    else if (queryType == '@QueryType.HybridStandard' || queryType == '@QueryType.HybridSemantic') {
                        // Hybrid search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using vector and keywords\n`;
                        mermaidDiagram += mermaidDiagramIntegratedVectorization;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using vector\n`;
                        mermaidDiagram += 'Index->>ACS: Vector search results\n';
                        mermaidDiagram += `ACS->>Index: Search using keywords\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Keyword search results\n';
                        mermaidDiagram += `ACS->>ACS: Merge (rerank) vector and keyword search results\n`;
                    }

                    if (queryType == '@QueryType.TextSemantic' || queryType == '@QueryType.HybridSemantic') {
                        // Semantic ranking.
                        mermaidDiagram += 'ACS->>ACS: L2 semantic ranking of search results\n';
                    }
                    mermaidDiagram += 'destroy ACS\n';
                    mermaidDiagram += `ACS-x${sourceParticipant}: Search results\n`;
                    return mermaidDiagram;
                }

                const getAzureOpenAIVectorSequenceDiagram = function () {
                    var mermaidDiagram = '';
                    mermaidDiagram += 'create participant Embedding as Embedding Model\n';
                    mermaidDiagram += 'AOAI->>Embedding: Generate vector for search query\n';
                    mermaidDiagram += 'destroy Embedding\n';
                    mermaidDiagram += 'Embedding-xAOAI: Vector for search query\n';
                    return mermaidDiagram;
                }

                const showSequenceDiagram = function () {
                    if (!settings.value.showExplanation) {
                        return;
                    }
                    var engine = searchRequest.value.engine;
                    var searchIndex = searchRequest.value.searchIndex;
                    var dataSource = searchRequest.value.dataSource;
                    var queryType = searchRequest.value.queryType;
                    var useIntegratedVectorization = searchRequest.value.useIntegratedVectorization;
                    var needsVector = (queryType == '@QueryType.Vector' || queryType == '@QueryType.HybridStandard' || queryType == '@QueryType.HybridSemantic');

                    var mermaidDiagram = 'sequenceDiagram\n';
                    mermaidDiagram += 'actor User as User\n';
                    mermaidDiagram += 'participant App as Search App\n';
                    if (engine == '@EngineType.AzureCognitiveSearch') {
                        // Azure AI Search.
                        mermaidDiagram += 'User->>App: Search query\n';
                        if (needsVector && !useIntegratedVectorization) {
                            mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                            mermaidDiagram += 'App->>AOAI: Generate vector for search query\n';
                            mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            mermaidDiagram += 'destroy AOAI\n';
                            mermaidDiagram += 'AOAI-xApp: Vector for search query\n';
                        }
                        mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('App', queryType, searchIndex, useIntegratedVectorization, true);
                        mermaidDiagram += 'App->>User: Search results\n';
                    } else if (engine == '@EngineType.AzureOpenAI') {
                        // Azure OpenAI.
                        mermaidDiagram += 'User->>App: Search query and history\n';
                        mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                        mermaidDiagram += 'App->>AOAI: Generate chat response\n';
                        if (dataSource == '@DataSourceType.AzureCognitiveSearch') {
                            // Using data source Azure AI Search.
                            if (needsVector) {
                                mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            }
                            mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('AOAI', queryType, searchIndex, false, false);
                            mermaidDiagram += 'AOAI->>AOAI: Build a prompt using the search results to ground the model\n';
                        }
                        // Chat completion.
                        mermaidDiagram += 'create participant GPT as GPT Model\n';
                        var gptInput = dataSource == '@DataSourceType.None' ? 'Generate chat response using search query and history' : 'Generate chat response using specialized prompt';
                        mermaidDiagram += `AOAI->>GPT: ${gptInput}\n`;
                        mermaidDiagram += 'destroy GPT\n';
                        mermaidDiagram += 'GPT-xAOAI: Chat response\n';
                        mermaidDiagram += 'destroy AOAI\n';
                        mermaidDiagram += 'AOAI-xApp: Chat response\n';
                        mermaidDiagram += 'App->>User: Chat response\n';
                    } else if (engine == '@EngineType.CustomOrchestration') {
                        // Custom orchestration.
                        mermaidDiagram += 'User->>App: Search query\n';
                        mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                        if (needsVector && !useIntegratedVectorization) {
                            mermaidDiagram += 'App->>AOAI: Generate vector for search query\n';
                            mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            mermaidDiagram += 'AOAI->>App: Vector for search query\n';
                        }
                        mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('App', queryType, searchIndex, useIntegratedVectorization, false);
                        mermaidDiagram += 'App->>App: Build a prompt using the search results to ground the model\n';
                        mermaidDiagram += `App->>AOAI: Generate chat response\n`;
                        mermaidDiagram += 'create participant GPT as GPT Model\n';
                        mermaidDiagram += `AOAI->>GPT: Generate chat response using specialized prompt\n`;
                        mermaidDiagram += 'destroy GPT\n';
                        mermaidDiagram += 'GPT-xAOAI: Chat response\n';
                        mermaidDiagram += 'destroy AOAI\n';
                        mermaidDiagram += 'AOAI-xApp: Chat response\n';
                        mermaidDiagram += 'App->>User: Chat response\n';
                    }

                    drawMermaid(mermaidDiagram);
                };

                showSequenceDiagram();

                return {
                    scenarios, selectedScenario, searchRequest, settings
                };
            }
        }).mount('#app');

        // Enable popovers after the Vue app is mounted as the trigger elements are dynamically added to the DOM. 
        const popoverTriggerList = document.querySelectorAll('[data-bs-toggle="popover"]');
        const popoverList = [...popoverTriggerList].map(popoverTriggerEl => new bootstrap.Popover(popoverTriggerEl, { html: true }));
    </script>
}
<h2 class="display-6 mb-3">@ViewData["Title"]</h2>

<form method="post" class="mb-3">

    <div class="card mb-3" >
        <div class="card-header">
            <div class="form-check form-check-inline form-switch">
                <input class="form-check-input" type="checkbox" role="switch" v-model="settings.showOptions">
                <label class="form-check-label">Show Options</label>
            </div>
        </div>
        <div class="card-body" v-show="settings.showOptions">
            <div class="mb-2">
                <label class="form-label">Predefined scenario</label>
                <div class="form-group">
                    <select class="form-select" v-model="selectedScenario">
                        <option v-bind:value="null">None</option>
                        <option v-for="scenario in scenarios" v-bind:value="scenario">{{ scenario.displayName }}</option>
                    </select>
                </div>
                <div class="alert alert-primary mt-2" v-if="selectedScenario && selectedScenario.description">
                    {{ selectedScenario.description }}
                </div>
            </div>
            <div class="mb-2">
                <label class="form-label">Engine</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-AzureCognitiveSearch" value="@EngineType.AzureCognitiveSearch" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-AzureCognitiveSearch">Azure AI Search</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Search through content with <a href='https://learn.microsoft.com/azure/search/search-what-is-azure-search' target='_blank'>Azure AI Search</a>. You can use <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>keyword</a> and optionally <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector-based</a> queries. The responses <i>always</i> come directly from the source data, rather than being generated by an AI model. You can optionally enable <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>semantic ranking</a> which <i>does</i> use AI, not to generate content but to increase the relevancy of the results."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-AzureOpenAI" value="@EngineType.AzureOpenAI" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-AzureOpenAI">Azure OpenAI</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use a <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt' target='_blank'>GPT model</a> in <a href='https://learn.microsoft.com/azure/ai-services/openai/overview' target='_blank'>Azure OpenAI</a> to perform a chat-based search experience. The responses are AI-generated rather than taken directly from the source data. When using <a href='https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data' target='_blank'>Azure OpenAI on your data</a>, the responses can be grounded in (and even limited to) the information in a private data source."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-CustomOrchestration" value="@EngineType.CustomOrchestration" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-CustomOrchestration">Custom orchestration</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use custom orchestration to perform the <a href='https://aka.ms/what-is-rag' target='_blank'>Retrieval Augmented Generation (RAG)</a> pattern. This is using <a href='https://learn.microsoft.com/semantic-kernel/overview/' target='_blank'>Semantic Kernel</a> behind the scenes to first retrieve relevant search results from Azure AI Search, and then build a prompt with those search results along with the original query to generate an answer (with citations)."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI' || searchRequest.engine == '@EngineType.CustomOrchestration'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">GPT model deployment</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="If you deployed other models (or versions) to Azure OpenAI than the default one, specify the deployment name here to use that instead."><i class="bi bi-info-circle"></i></span>
                <input type="text" class="form-control" name="@nameof(SearchRequest.OpenAIGptDeployment)" id="searchRequest-OpenAIGptDeployment" v-model="searchRequest.openAIGptDeployment">
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">System role information</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality, tell it what it should and shouldn't answer, and tell it how to format responses."><i class="bi bi-info-circle"></i></span>
                <input type="text" class="form-control" name="@nameof(SearchRequest.SystemRoleInformation)" id="searchRequest-SystemRoleInformation" v-model="searchRequest.systemRoleInformation">
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.CustomOrchestration'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">Prompt template</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Define the prompt that will be sent to the AI model. Use <code>{{$query}}</code> to refer to the original query and <code>{{$sources}}</code> to refer to the relevant data sources as retrieved from Azure AI Search."><i class="bi bi-info-circle"></i></span>
                <textarea class="form-control" name="@nameof(SearchRequest.CustomOrchestrationPrompt)" id="searchRequest-CustomOrchestrationPrompt" v-model="searchRequest.customOrchestrationPrompt" rows="10"></textarea>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI'">
                <label class="form-label">Data source (Azure OpenAI &quot;on your data&quot;)</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="When using a private data source, <a href='https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data' target='_blank'>Azure OpenAI on your data</a> orchestrates the <a href='https://aka.ms/what-is-rag' target='_blank'>Retrieval Augmented Generation (RAG)</a> pattern. This means your search query will first be used to retrieve the most relevant documents (or preferably <i>smaller chunks of those documents</i>) from your private data source. Those search results are then used as context in the prompt that gets sent to the AI model, along with the original search query. This allows the AI model to generate a response based on the most relevant source data, rather than the public data that was used to train the model."><i class="bi bi-info-circle"></i></span>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.DataSource)" id="searchRequest-DataSource-None" value="@DataSourceType.None" v-model="searchRequest.dataSource">
                        <label class="form-check-label" for="searchRequest-DataSource-None">None</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Don't use a private data source, let the AI model respond using only the data it was trained on."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.DataSource)" id="searchRequest-DataSource-AzureCognitiveSearch" value="@DataSourceType.AzureCognitiveSearch" v-model="searchRequest.dataSource">
                        <label class="form-check-label" for="searchRequest-DataSource-AzureCognitiveSearch">Azure AI Search</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use source data from an Azure AI Search index. For best results, you should use the <code>Chunks</code> index, as this contains smaller and typically more contextually relevant pieces of information. This makes the prompt that is sent to the AI model better suited to generate a meaningful response from."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline form-switch" v-show="searchRequest.dataSource != '@DataSourceType.None'">
                        <input class="form-check-input" type="checkbox" role="switch" name="@nameof(SearchRequest.LimitToDataSource)" id="searchRequest-LimitToDataSource" value="true" v-model="searchRequest.limitToDataSource">
                        <input type="hidden" name="@nameof(SearchRequest.LimitToDataSource)" value="false" />
                        <label class="form-check-label" for="searchRequest-LimitToDataSource">Limit to your data</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Limit responses to your data content only, not including the data that was used for training the model."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None')">
                <label class="form-label">Search index</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.SearchIndex)" id="searchRequest-SearchIndex-Documents" value="@SearchIndexType.Documents" v-model="searchRequest.searchIndex">
                        <label class="form-check-label" for="searchRequest-SearchIndex-Documents">Documents</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Contains the full text content of the source data, as <a href='https://learn.microsoft.com/azure/search/search-blob-storage-integration' target='_blank'>extracted from your files in Blob storage</a>. Each file and its entire contents are stored as a single document in the search index, which can therefore be quite large. For regular keyword search or using semantic ranking that works great, but large content may cause issues with token limits, prompt size and content relevancy in AI applications."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.SearchIndex)" id="searchRequest-SearchIndex-Chunks" value="@SearchIndexType.Chunks" v-model="searchRequest.searchIndex">
                        <label class="form-check-label" for="searchRequest-SearchIndex-Chunks">Chunks</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Each file in the <code>Documents</code> index is automatically processed by an <a href='https://learn.microsoft.com/azure/search/cognitive-search-working-with-skillsets' target='_blank'>Azure AI Search skillset</a>. This splits it into smaller pieces (chunks) and then uses an <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings' target='_blank'>embedding model in Azure OpenAI</a> to generate a vector representation of that piece of content. Each chunk's content and this vector are then stored as a separate document in the search index. This makes it much better suited to find the most relevant piece of content by using <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector (or hybrid) search</a> search, and reduces the content size to make an AI prompt fit within token limits."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None')">
                <label class="form-label">Query type</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-TextStandard" value="@QueryType.TextStandard" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-TextStandard">Standard keyword</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use regular <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>keyword search</a>."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-TextSemantic" value="@QueryType.TextSemantic" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-TextSemantic">Semantic keyword</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>semantic ranking</a>, which returns more relevant results by applying language understanding to initial search results. It can also return <a href='https://learn.microsoft.com/azure/search/semantic-how-to-query-request' target='_blank'>semantic captions</a> (parts of a document that best summarize the content) and even <a href='https://learn.microsoft.com/azure/search/semantic-answers' target='_blank'>semantic answers</a> (direct answers to queries that look like a question). In all cases, the responses aren't AI-generated but come directly from the source data."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline" v-show="searchRequest.searchIndex != '@SearchIndexType.Documents'">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-Vector" value="@QueryType.Vector" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-Vector">Vector only</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="First send the search query to an <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings' target='_blank'>embedding model in Azure OpenAI</a> to generate a vector representing the query itself. Then perform a <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> to retrieve the nearest neighbors in vector space from the chunked and vectorized documents in the <code>Chunks</code> index. This should return results that are semantically similar to the query, as determined by the embedding model's vector representations."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline" v-show="searchRequest.searchIndex != '@SearchIndexType.Documents'">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-HybridStandard" value="@QueryType.HybridStandard" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-HybridStandard">Standard hybrid (keyword + vector)</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Combine the results of a <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> with the regular <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>keyword search</a> results into a single ranked response."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline" v-show="searchRequest.searchIndex != '@SearchIndexType.Documents'">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-HybridSemantic" value="@QueryType.HybridSemantic" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-HybridSemantic">Semantic hybrid (keyword + vector)</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Combine the results of <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> and <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>search with semantic ranking</a> into a single ranked response. Compared to standard hybrid search, this provides even more accuracy with L2 reranking using the same language models that power Bing."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None') && (searchRequest.queryType == '@QueryType.TextStandard' || searchRequest.queryType == '@QueryType.HybridStandard')">
                <label class="form-label">Query syntax</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QuerySyntax)" id="searchRequest-QuerySyntax-Simple" value="@QuerySyntax.Simple" v-model="searchRequest.querySyntax">
                        <label class="form-check-label" for="searchRequest-QuerySyntax-Simple">Simple</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Uses the <a href='https://learn.microsoft.com/azure/search/query-simple-syntax' target='_blank'>simple query syntax</a> for searches. Search text is interpreted using a simple query language that allows for symbols such as <code>+</code>, <code>*</code> and <code>&quot;&quot;</code>."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QuerySyntax)" id="searchRequest-QuerySyntax-Lucene" value="@QuerySyntax.Lucene" v-model="searchRequest.querySyntax">
                        <label class="form-check-label" for="searchRequest-QuerySyntax-Lucene">Lucene</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Uses the <a href='https://learn.microsoft.com/azure/search/query-lucene-syntax' target='_blank'>full Lucene query syntax</a> for searches. Search text is interpreted using the Lucene query language which allows field-specific and weighted searches, as well as other advanced features."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None')">
                <label class="form-label">Result parameters</label>
                <div class="row row-cols-lg-auto g-3 align-items-center">
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Document count
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="The number of documents to return."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="number" class="form-control form-control-small" name="@nameof(SearchRequest.DocumentCount)" value="@Model.SearchRequest.DocumentCount" />
                        </div>
                    </div>
                    <div class="col-12" v-show="searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.AzureCognitiveSearch'">
                        <div class="input-group">
                            <div class="input-group-text">
                                Strictness
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Sets the threshold to categorize documents as relevant to your queries. Raising the value means a higher threshold for relevance and filters out more less-relevant documents for responses. Setting this value too high might cause the model to fail to generate responses due to limited available documents."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="number" class="form-control form-control-small" name="@nameof(SearchRequest.Strictness)" value="@Model.SearchRequest.Strictness" />
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None') && (searchRequest.queryType == '@QueryType.Vector' || searchRequest.queryType == '@QueryType.HybridStandard' || searchRequest.queryType == '@QueryType.HybridSemantic')">
                <label class="form-label">Vector parameters</label>
                <div class="row row-cols-lg-auto g-3 align-items-center">
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Nearest neighbors
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="The number of nearest neighbors to return from vector search. When using semantic ranking, this should be set to a high enough number in order to get sufficient candidates for the reranking."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="number" class="form-control form-control-small" name="@nameof(SearchRequest.VectorNearestNeighborsCount)" value="@Model.SearchRequest.VectorNearestNeighborsCount" />
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="form-check form-check-inline form-switch" v-show="searchRequest.engine != '@EngineType.AzureOpenAI'">
                            <input class="form-check-input" type="checkbox" role="switch" name="@nameof(SearchRequest.UseIntegratedVectorization)" id="searchRequest-UseIntegratedVectorization" value="true" v-model="searchRequest.useIntegratedVectorization">
                            <input type="hidden" name="@nameof(SearchRequest.UseIntegratedVectorization)" value="false" />
                            <label class="form-check-label" for="searchRequest-UseIntegratedVectorization">Use integrated vectorization</label>
                            <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use <a href='https://learn.microsoft.com/azure/search/vector-search-integrated-vectorization' target='_blank'>integrated vectorization</a> to let Azure AI Search generate the vector embedding for the search query text, rather than the app doing that upfront and sending the vector directly to the search service."><i class="bi bi-info-circle"></i></span>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.CustomOrchestration' || searchRequest.engine == '@EngineType.AzureOpenAI'">
                <label class="form-label">Model parameters</label>
                <div class="row row-cols-lg-auto g-3 align-items-center">
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Max tokens
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Set a limit on the number of tokens that the model will use to generate the response, to avoid running into token limitations (as token size is counted against the combined prompt and response). One token is roughly 4 characters for typical English text."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.MaxTokens)" value="@Model.SearchRequest.MaxTokens">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Temperature
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Controls randomness. Lowering the temperature means that the model will produce more repetitive and deterministic responses. Increasing the temperature will result in more unexpected or creative responses. Try adjusting temperature or <code>Top P</code> but not both. <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/completions' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.Temperature)" value="@Model.SearchRequest.Temperature">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Top P
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Similar to temperature, this controls randomness but uses a different method. Lowering <code>Top P</code> will narrow the model's token selection to likelier tokens. Increasing <code>Top P</code> will let the model choose from tokens with both high and low likelihood. Try adjusting temperature or <code>Top P</code> but not both. <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/completions' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.TopP)" value="@Model.SearchRequest.TopP">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Frequency penalty
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Reduce the chance of repeating a token proportionally based on how often it has appeared in the text so far. This decreases the likelihood of repeating the exact same text in a response. <a href='https://platform.openai.com/docs/guides/gpt/parameter-details' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.FrequencyPenalty)" value="@Model.SearchRequest.FrequencyPenalty">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Presence penalty
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Reduce the chance of repeating any token that has appeared in the text at all so far. This increases the likelihood of introducing new topics in a response. <a href='https://platform.openai.com/docs/guides/gpt/parameter-details' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.PresencePenalty)" value="@Model.SearchRequest.PresencePenalty">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Stop sequences
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Make the model end its response at a desired point. The model response will end before the specified sequence, so it won't contain the stop sequence text. For ChatGPT, using <code>&lt;|im_end|&gt;</code> ensures that the model response doesn't generate a follow-up user query. You can include as many as four stop sequences, separated by commas."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control" name="@nameof(SearchRequest.StopSequences)" value="@Model.SearchRequest.StopSequences">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-header">
            <div class="form-check form-check-inline form-switch">
                <input class="form-check-input" type="checkbox" role="switch" v-model="settings.showExplanation">
                <label class="form-check-label">What's going on?</label>
            </div>
        </div>
        <div class="card-body" v-show="settings.showExplanation">
            <pre id="mermaid" class="mermaid"></pre>
        </div>
    </div>

    @if (Model.SearchResponse?.History != null && Model.SearchResponse.History.Any())
    {
        <div class="message-list mb-4">
            @foreach (var item in Model.SearchResponse.History)
            {
                var cssClass = Model.SearchResponse.History.IndexOf(item) % 2 == 0 ? "border-primary-subtle float-end text-end" : "border-info float-start";

                <input type="hidden" name="history[]" value="@item" />
                <div class="message-list-item mt-3 p-2 w-75 border rounded search-answer @cssClass">@Html.Raw(item)</div>
                <div class="clearfix"></div>
            }
        </div>
    }
    else
    {
        if (!string.IsNullOrWhiteSpace(Model.SearchRequest.Query))
        {
            <h3 class="mb-3">Search results for <code>@Model.SearchRequest.Query</code></h3>
        }
    }

    <div class="input-group">
        <input type="text" class="form-control border-primary" placeholder="Search or ask anything" name="@nameof(SearchRequest.Query)" />
        <button class="btn btn-outline-primary" type="submit"><i class="bi bi-send"></i> Send</button>
    </div>
</form>

<partial name="_SearchResponse" model="Model.SearchResponse" />